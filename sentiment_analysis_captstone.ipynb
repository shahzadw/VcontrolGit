{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Spacy model \n",
    "nlp= spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    This product so far has not disappointed. My c...\n",
      "1    great for beginner or experienced person. Boug...\n",
      "2    Inexpensive tablet for him to use and learn on...\n",
      "3    I've had my Fire HD 8 two weeks now and I love...\n",
      "4    I bought this for my grand daughter when she c...\n",
      "Name: reviews.text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#creating DataFrame by loading DataSet and selecting the relevant column for data cleaning\n",
    "df_amazon = pd.read_csv(\"amazon_product_reviews.csv\", sep=',', low_memory=False)\n",
    "df_amazon_reviews_column = df_amazon['reviews.text'].head()\n",
    "print(df_amazon_reviews_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    this product so far has not disappointed. my c...\n",
      "1    great for beginner or experienced person. boug...\n",
      "2    inexpensive tablet for him to use and learn on...\n",
      "3    i've had my fire hd 8 two weeks now and i love...\n",
      "4    i bought this for my grand daughter when she c...\n",
      "Name: reviews.text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#converting everything to lower case\n",
    "a_row_selection = df_amazon_reviews_column.loc[:] #selecting all rows \n",
    "b_lower_case = a_row_selection.str.lower() #converting everything into lower case\n",
    "print(b_lower_case) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        this product so far has not disappointed my ch...\n",
      "1        great for beginner or experienced person bough...\n",
      "2        inexpensive tablet for him to use and learn on...\n",
      "3        i've had my fire hd 8 two weeks now and i love...\n",
      "4        i bought this for my grand daughter when she c...\n",
      "                               ...                        \n",
      "34655    this is not appreciably faster than any other ...\n",
      "34656    amazon should include this charger with the ki...\n",
      "34657    love my kindle fire but i am really disappoint...\n",
      "34658    i was surprised to find it did not come with a...\n",
      "34659    to spite the fact that i have nothing but good...\n",
      "Name: reviews.text, Length: 34660, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#removing all punctuation and null rows\n",
    "new_df = b_lower_case.dropna()\n",
    "y= df_amazon[\"reviews.text\"].str.replace(r'[\\.\\,\\?\\!\\$\\(\\)\\/\"\\&\\-]',\"\",regex=True)\n",
    "clean_df= y.str.lower()\n",
    "print(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [\"this\", \"product\", \"so\", \"far\", \"has\", \"not\",...\n",
      "1    [\"great\", \"for\", \"beginner\", \"or\", \"experience...\n",
      "2    [\"inexpensive\", \"tablet\", \"for\", \"him\", \"to\", ...\n",
      "3    [\"i\", \"'ve\", \"had\", \"my\", \"fire\", \"hd\", \"8\", \"...\n",
      "4    [\"i\", \"bought\", \"this\", \"for\", \"my\", \"grand\", ...\n",
      "Name: reviews.text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# The code below works - Only doing it for the first 5 rows to check the code works\n",
    "clean_df['tokenized']= clean_df.iloc[:5].apply(lambda x: ['\"'+ token.text +'\"' for token in nlp(x)])\n",
    "tokenized_df=clean_df['tokenized']\n",
    "print(tokenized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             [\"this\", \"product\", \"so\", \"far\", \"has\", \"not\",...\n",
      "1             [\"great\", \"for\", \"beginner\", \"or\", \"experience...\n",
      "2             [\"inexpensive\", \"tablet\", \"for\", \"him\", \"to\", ...\n",
      "3             [\"i\", \"'ve\", \"had\", \"my\", \"fire\", \"hd\", \"8\", \"...\n",
      "4             [\"i\", \"bought\", \"this\", \"for\", \"my\", \"grand\", ...\n",
      "lemmatized    0    [\", this, \", \", product, \", \", so, \", \", ...\n",
      "Name: reviews.text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Lemmatizing \n",
    "def lemmatize_text(text):\n",
    "    doc= nlp(\" \".join(text))\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "tokenized_df['lemmatized'] = tokenized_df.apply(lemmatize_text)\n",
    "print (tokenized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   [\"this\", \"product\", \"so\", \"far\", \"has\", \"not\",...\n",
      "1                   [\"great\", \"for\", \"beginner\", \"or\", \"experience...\n",
      "2                   [\"inexpensive\", \"tablet\", \"for\", \"him\", \"to\", ...\n",
      "3                   [\"i\", \"'ve\", \"had\", \"my\", \"fire\", \"hd\", \"8\", \"...\n",
      "4                   [\"i\", \"bought\", \"this\", \"for\", \"my\", \"grand\", ...\n",
      "lemmatized          0    [\", this, \", \", product, \", \", so, \", \", ...\n",
      "sentiment_scores    0    {'neg': 0.0, 'neu': 0.599, 'pos': 0.401, ...\n",
      "Name: reviews.text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Sentiment analyses \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "#using sentiment intesity analyzer function\n",
    "sid= SentimentIntensityAnalyzer()\n",
    "\n",
    "#function to get sentiment scores\n",
    "def get_sentiment_scores(text):\n",
    "    return sid.polarity_scores(text)\n",
    "\n",
    "#applying sentiment analysis to the lemmatized text\n",
    "tokenized_df['sentiment_scores'] = tokenized_df['lemmatized'].apply(lambda x: get_sentiment_scores(\" \".join(x)))\n",
    "print(tokenized_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
